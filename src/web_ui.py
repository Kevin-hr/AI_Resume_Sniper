"""
Web UI / Webç•Œé¢
Streamlit-based web interface for HRD's Blackbox (formerly AI Resume Sniper).
"""

import sys
import streamlit as st
import os
import pandas as pd
import re
import json
from pathlib import Path
from dotenv import load_dotenv
import plotly.graph_objects as go

# Load .env file with override to ensure local settings take precedence
load_dotenv(override=True)

# Add parent directory to path for imports
_current_dir = Path(__file__).parent.resolve()
_parent_dir = _current_dir.parent
if str(_parent_dir) not in sys.path:
    sys.path.insert(0, str(_parent_dir))

# Import from new plugin architecture
from src.core.engine import ResumeSniperEngine
from src.core.config import get_config
from src.plugins.document_parsers import get_parser_for_file
from src.core.exceptions import PluginNotFoundError, UnsupportedFormatError

# --- Page Config ---
st.set_page_config(
    page_title="å¤©ç”Ÿæˆ‘æ‰ | HRD çš„é»‘åŒ£å­",
    page_icon="ğŸ’¼",
    layout="wide"
)

# --- Translations ---
TRANSLATIONS = {
    'en': {
        # Pain Points / ç”¨æˆ·ç—›ç‚¹
        'pain1_title': 'ğŸ˜° Resume Ghosted',
        'pain1_desc': 'Sent 100+ applications, zero callbacks. What\'s wrong with my resume?',
        'pain2_title': 'ğŸ˜• Lost in the Market',
        'pain2_desc': 'Don\'t know my real market value. Am I undercharging myself?',
        'pain3_title': 'ğŸ˜“ Achievements to Duties',
        'pain3_desc': 'My resume reads like a job description, not an achievement log.',
        # Solution / çˆ½ç‚¹
        'solution1_title': 'ğŸ¯ See Why You\'re Rejected',
        'solution1_desc': 'Know exactly why HR rejects you in 6 seconds. Fix it fast.',
        'solution2_title': 'ğŸ’ Know Your Worth',
        'solution2_desc': 'Discover hidden assets and market positioning.',
        'solution3_title': 'âœ¨ STAR Rewrite',
        'solution3_desc': 'Turnå¹³æ·¡æè¿° into é‡åŒ–æˆæœ that HR loves.',
        # Tabs
        'tab_diagnostic': 'ğŸ” Who Am I?',
        'tab_career': 'ğŸ’¼ Resume Audit',
        'tab_side_hustle': 'ğŸš€ Side Hustle',
        'tab_headhunter': 'ğŸ’° Recruiter Mode',
        # Actions
        'btn_diagnostic': 'ğŸ” Diagnose My Value',
        'btn_analyze': 'ğŸ¯ Audit My Resume',
        'btn_hustle': 'ğŸ’° Smart JD (Coming Soon)',
        'btn_headhunter': 'ğŸ’¼ Generate Candidate Packet',
        # Form labels
        'resume_label': 'Your Resume',
        'upload_resume': 'Upload (PDF/DOCX/Txt)',
        'paste_resume': 'Or paste here...',
        'jd_label': 'Target Job Description',
        'upload_jd': 'Upload JD',
        'paste_jd': 'Or paste JD here...',
        # Status
        'no_resume': 'Please upload your resume.',
        'no_jd': 'Please provide a job description.',
        'processing_diag': 'ğŸ§  HRD is analyzing your hidden value...',
        'processing_audit': 'ğŸ¯ Auditing your resume against the JD...',
        'diag_complete': 'âœ… Diagnosis Complete',
        'audit_complete': 'âœ… Audit Complete',
        'footer': '15-year HRD experience in your pocket',
        # Settings
        'settings': 'Settings',
        'provider': 'LLM Provider',
        'api_key': 'API Key',
        'api_key_help': 'Leave empty to use .env',
        'model': 'Model Name',
        'persona': 'Analysis Persona',
        'use_cache': 'Enable Cache',
        'engine_error': 'Engine not initialized. Please check sidebar settings.',
    },
    'zh': {
        # Pain Points / ç”¨æˆ·ç—›ç‚¹
        'pain1_title': 'ğŸ˜° ç®€å†çŸ³æ²‰å¤§æµ·',
        'pain1_desc': 'æŠ•äº†100ä»½ï¼Œä¸€ä¸ªå›å¤éƒ½æ²¡æœ‰ï¼Ÿåˆ°åº•å“ªé‡Œå‡ºäº†é—®é¢˜ï¼Ÿ',
        'pain2_title': 'ğŸ˜• ä¸çŸ¥é“è‡ªå·±å€¼å¤šå°‘é’±',
        'pain2_desc': 'å¸‚åœºå®šä½æ¨¡ç³Šï¼Œè–ªèµ„è°ˆåˆ¤å¿ƒé‡Œæ²¡åº•ã€‚',
        'pain3_title': 'ğŸ˜“ å†™æˆå²—ä½èŒè´£è€Œä¸æ˜¯æˆç»©',
        'pain3_desc': 'ç®€å†å†™çš„æ˜¯"åšäº†ä»€ä¹ˆ"ï¼Œæ²¡æœ‰"åšæˆä»€ä¹ˆ"ã€‚',
        # Solution / çˆ½ç‚¹
        'solution1_title': 'ğŸ¯ 6ç§’è¢«æ‹’çš„åŸå› ï¼Œä¸€ç›®äº†ç„¶',
        'solution1_desc': 'ç²¾å‡†å®šä½ç®€å†ç¡¬ä¼¤ï¼Œå‘Šè¯‰ä½ æ€ä¹ˆæ”¹ã€‚',
        'solution2_title': 'ğŸ’ æŒ–æ˜ä½ çš„éšæ€§ä»·å€¼',
        'solution2_desc': 'å‘ç°ä½ æ²¡æ„è¯†åˆ°çš„å¸‚åœºä»·å€¼ã€‚',
        'solution3_title': 'âœ¨ è‡ªåŠ¨ STAR é‡å†™',
        'solution3_desc': 'æŠŠå¹³æ·¡æè¿°æ”¹æˆHRçˆ±çœ‹çš„é‡åŒ–æˆæœã€‚',
        # Tabs
        'tab_diagnostic': 'ğŸ” æˆ‘æ˜¯è°ï¼Ÿ(æ·±åº¦è¯Šæ–­)',
        'tab_career': 'ğŸ’¼ ç®€å†åŒ¹é… (èŒåœºçªå›´)',
        'tab_side_hustle': 'ğŸš€ å‰¯ä¸šå˜ç° (æ™ºèƒ½ JD)',
        'tab_headhunter': 'ğŸ’° çŒå¤´æ¨¡å¼ (æ¨èæŠ¥å‘Š)',
        # Actions
        'btn_diagnostic': 'ğŸ” æ·±åº¦æŒ–æ˜æˆ‘çš„ä»·å€¼',
        'btn_analyze': 'ğŸ¯ å¸®æˆ‘è¿‡ HR è¿™ä¸€å…³',
        'btn_hustle': 'ğŸš€ ç”Ÿæˆå‰¯ä¸š JD',
        'btn_headhunter': 'ğŸ“ ç”Ÿæˆå€™é€‰äººæ¨èæŠ¥å‘Š',
        # Form labels
        'resume_label': 'ä¸Šä¼ ä½ çš„ç®€å†',
        'upload_resume': 'é€‰æ‹©æ–‡ä»¶ (PDF/DOCX/Txt)',
        'paste_resume': 'æˆ–ç›´æ¥ç²˜è´´ç®€å†å†…å®¹...',
        'jd_label': 'ç›®æ ‡èŒä½æè¿° (JD)',
        'upload_jd': 'ä¸Šä¼  JD æ–‡ä»¶',
        'paste_jd': 'æˆ–ç›´æ¥ç²˜è´´ JD å†…å®¹...',
        # Status
        'no_resume': 'è¯·å…ˆä¸Šä¼ æˆ–ç²˜è´´ç®€å†',
        'no_jd': 'è¯·å…ˆä¸Šä¼ æˆ–ç²˜è´´èŒä½æè¿°',
        'processing_diag': 'ğŸ§  HRD æ­£åœ¨æ·±åº¦åˆ†æä½ çš„ä»·å€¼...',
        'processing_audit': 'ğŸ¯ æ­£åœ¨å¯¹æ¯”ç®€å†å’ŒJDï¼Œæ‰¾å‡ºå·®è·...',
        'diag_complete': 'âœ… æ·±åº¦è¯Šæ–­å®Œæˆ',
        'audit_complete': 'âœ… ç®€å†åˆ†æå®Œæˆ',
        'footer': 'æŠŠ15å¹´HRDç»éªŒè£…è¿›å£è¢‹',
        # Settings
        'settings': 'è®¾ç½®',
        'provider': 'AI æ¨¡å‹æä¾›å•†',
        'api_key': 'API Key (å¯é€‰)',
        'api_key_help': 'ç•™ç©ºåˆ™ä½¿ç”¨ .env é…ç½®',
        'model': 'æ¨¡å‹åç§°',
        'persona': 'åˆ†æè§’è‰²',
        'use_cache': 'å¯ç”¨ç¼“å­˜',
        'engine_error': 'å¼•æ“æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥å·¦ä¾§è®¾ç½®ã€‚',
    }
}

def t(key):
    lang = st.session_state.get('lang', 'zh')
    return TRANSLATIONS[lang].get(key, key)

# --- Helper Functions ---
def get_content_list(uploaded_files, text_area_content, label):
    """Returns a list of dictionaries: [{'name': '...', 'content': '...'}]"""
    content_list = []

    # Process Uploaded Files
    if uploaded_files:
        for uploaded_file in uploaded_files:
            # Save temp file
            with open(uploaded_file.name, "wb") as f:
                f.write(uploaded_file.getbuffer())

            try:
                parser = get_parser_for_file(uploaded_file.name)
                doc = parser.parse(uploaded_file.name)
                content_list.append({
                    "name": uploaded_file.name,
                    "content": doc.content,
                    "type": doc.file_type
                })
            except UnsupportedFormatError:
                st.error(f"âŒ Unsupported format: {uploaded_file.name}")
            except Exception as e:
                st.error(f"âŒ Error parsing {uploaded_file.name}: {e}")
            finally:
                if os.path.exists(uploaded_file.name):
                    os.remove(uploaded_file.name)

    # Process Text Area
    if text_area_content and text_area_content.strip():
        name = f"Manual {label} Input"
        content_list.append({
            "name": name,
            "content": text_area_content,
            "type": "text"
        })

    return content_list

def extract_score(report_text):
    try:
        match = re.search(r"Score.*?(\d+)", report_text, re.IGNORECASE)
        if match:
            return int(match.group(1))
    except:
        pass
    return None

def get_score_color(score):
    if score is None: return "gray"
    if score >= 80: return "green"
    if score >= 60: return "orange"
    return "red"

def parse_and_preview_file(uploaded_file):
    """Parse uploaded file and return content with preview."""
    if uploaded_file is None:
        return None, None

    # Save temp file
    temp_path = uploaded_file.name
    with open(temp_path, "wb") as f:
        f.write(uploaded_file.getbuffer())

    try:
        parser = get_parser_for_file(temp_path)
        doc = parser.parse(temp_path)
        content = doc.content
        preview = content[:500] + "..." if len(content) > 500 else content
        return content, preview
    except UnsupportedFormatError:
        return None, f"âŒ ä¸æ”¯æŒçš„æ ¼å¼: {uploaded_file.name}"
    except Exception as e:
        return None, f"âŒ è§£æé”™è¯¯: {e}"
    finally:
        if os.path.exists(temp_path):
            os.remove(temp_path)

def extract_radar_data(report_text):
    """Extract radar chart data from report JSON block."""
    try:
        # Look for JSON block with radar data
        pattern = r'```json\s*(\{[^`]*"radar"[^`]*\})\s*```'
        match = re.search(pattern, report_text, re.DOTALL)
        if match:
            data = json.loads(match.group(1))
            return data.get("radar", {})

        # Fallback: try to find inline JSON
        pattern2 = r'\{"radar":\s*\{[^}]+\}\}'
        match2 = re.search(pattern2, report_text)
        if match2:
            data = json.loads(match2.group(0))
            return data.get("radar", {})
    except:
        pass
    return None

def render_radar_chart(radar_data):
    """Render radar chart using Plotly."""
    if not radar_data:
        return None

    categories = list(radar_data.keys())
    values = list(radar_data.values())

    # Close the radar chart
    categories = categories + [categories[0]]
    values = values + [values[0]]

    fig = go.Figure()

    fig.add_trace(go.Scatterpolar(
        r=values,
        theta=categories,
        fill='toself',
        name='èƒ½åŠ›é›·è¾¾',
        line_color='#667eea',
        fillcolor='rgba(102, 126, 234, 0.3)'
    ))

    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True,
                range=[0, 100],
                tickfont=dict(size=10)
            ),
            angularaxis=dict(
                tickfont=dict(size=12)
            )
        ),
        showlegend=False,
        title=dict(
            text="ğŸ“Š èƒ½åŠ›é›·è¾¾å›¾",
            x=0.5,
            font=dict(size=16)
        ),
        height=400,
        margin=dict(l=60, r=60, t=60, b=60)
    )

    return fig

# --- Main UI ---

# Sidebar
with st.sidebar:
    st.image("https://img.icons8.com/color/96/000000/resume.png", width=64)
    st.markdown("## HRD's Blackbox")
    
    lang_select = st.selectbox("Language / è¯­è¨€", ["zh", "en"], index=0)
    st.session_state['lang'] = lang_select
    
    st.divider()
    st.markdown(f"### {t('settings')}")
    
    # Init Engine Logic
    config = get_config()
    
    # å¼ºåˆ¶ä½¿ç”¨ DeepSeek
    provider = st.selectbox(t('provider'), ["deepseek"], index=0)
    api_key = st.text_input(t('api_key'), type="password", help=t('api_key_help'))
    if api_key:
        os.environ[f"{provider.upper()}_API_KEY"] = api_key
        
    # è·å–é»˜è®¤æ¨¡å‹
    default_model_name = "deepseek-chat"
        
    model = st.text_input(t('model'), value=default_model_name)
    persona_key = st.selectbox(t('persona'), ["hrbp", "coach", "product_manager", "headhunter"], index=0)
    use_cache = st.checkbox(t('use_cache'), value=True)
    
    if st.button("Reload Engine"):
        if 'engine' in st.session_state:
            del st.session_state['engine']

# Initialize Engine
if 'engine' not in st.session_state:
    try:
        st.session_state.engine = ResumeSniperEngine(llm_provider=provider)
    except Exception as e:
        st.sidebar.error(f"Engine Init Error: {e}")

# ========================================
# ğŸš€ HOMEPAGE - ç”¨æˆ·è§†è§’
# ========================================

st.markdown("""
<div style='text-align: center; padding: 20px 0;'>
    <h1 style='font-size: 2.5em; margin-bottom: 10px;'>ğŸ’¼ å¤©ç”Ÿæˆ‘æ‰</h1>
    <p style='font-size: 1.2em; color: #666;'>æŠŠ15å¹´HRDç»éªŒè£…è¿›å£è¢‹</p>
</div>
""", unsafe_allow_html=True)

# --- ç—›ç‚¹åŒº ---
st.markdown("### ğŸ˜° ä½ çš„å›°æ‰°")
col_pain1, col_pain2, col_pain3 = st.columns(3)
with col_pain1:
    st.error(f"**{t('pain1_title')}**\n\n{t('pain1_desc')}")
with col_pain2:
    st.warning(f"**{t('pain2_title')}**\n\n{t('pain2_desc')}")
with col_pain3:
    st.info(f"**{t('pain3_title')}**\n\n{t('pain3_desc')}")

st.markdown("---")

# --- çˆ½ç‚¹åŒº ---
st.markdown("### âœ¨ æˆ‘æ¥å¸®ä½ ")
col_sol1, col_sol2, col_sol3 = st.columns(3)
with col_sol1:
    st.success(f"**{t('solution1_title')}**\n\n{t('solution1_desc')}")
with col_sol2:
    st.success(f"**{t('solution2_title')}**\n\n{t('solution2_desc')}")
with col_sol3:
    st.success(f"**{t('solution3_title')}**\n\n{t('solution3_desc')}")

st.markdown("---")

# --- åŠŸèƒ½é€‰æ‹© ---
st.markdown("### ğŸ¯ é€‰æ‹©ä½ çš„éœ€æ±‚")
tab_career, tab_diag, tab_hustle, tab_headhunter = st.tabs([t('tab_career'), t('tab_diagnostic'), t('tab_side_hustle'), t('tab_headhunter')])

# --- Tab 1: Career (ç®€å†ä¼˜åŒ–/ç²¾å‡†ç‹™å‡») ---
with tab_career:
    st.markdown("""
    **ğŸ’¼ ç®€å†ä¼˜åŒ–ï¼šä½ çš„ç®€å†èƒ½é€šè¿‡HRçš„6ç§’ç­›é€‰å—ï¼Ÿ**

    ä¸Šä¼ ç®€å† + ç›®æ ‡å²—ä½JDï¼Œç²¾å‡†å®šä½å·®è·ï¼Œç»™å‡ºSTARé‡å†™å»ºè®®ã€‚
    """)

    col1, col2 = st.columns(2)
    with col1:
        st.markdown(f"**{t('resume_label')}**")
        uploaded_resumes_career = st.file_uploader(
            t('upload_resume'),
            type=['txt', 'md', 'pdf', 'docx'],
            accept_multiple_files=True,
            key="career_resume"
        )
        resume_text_career = st.text_area(
            t('paste_resume'),
            height=200,
            key="career_resume_text"
        )

        # Show parsed preview for resume
        if uploaded_resumes_career:
            for uf in uploaded_resumes_career:
                content, preview = parse_and_preview_file(uf)
                if content:
                    with st.expander(f"ğŸ“„ å·²è§£æ: {uf.name}", expanded=False):
                        st.text_area("æå–çš„æ–‡æœ¬å†…å®¹", preview, height=150, disabled=True, key=f"preview_resume_{uf.name}")
                else:
                    st.error(preview)

    with col2:
        st.markdown(f"**{t('jd_label')}**")
        uploaded_jds_career = st.file_uploader(
            t('upload_jd'),
            type=['txt', 'md', 'pdf', 'docx'],
            accept_multiple_files=True,
            key="career_jd"
        )
        jd_text_career = st.text_area(
            t('paste_jd'),
            height=200,
            key="career_jd_text"
        )

        # Show parsed preview for JD
        if uploaded_jds_career:
            for uf in uploaded_jds_career:
                content, preview = parse_and_preview_file(uf)
                if content:
                    with st.expander(f"ğŸ“„ å·²è§£æ: {uf.name}", expanded=False):
                        st.text_area("æå–çš„æ–‡æœ¬å†…å®¹", preview, height=150, disabled=True, key=f"preview_jd_{uf.name}")
                else:
                    st.error(preview)

    if st.button(t('btn_analyze'), type="primary", use_container_width=True):
        if 'engine' not in st.session_state:
            st.error(t('engine_error'))
        else:
            resume_list = get_content_list(uploaded_resumes_career, resume_text_career, "Resume")
            jd_list = get_content_list(uploaded_jds_career, jd_text_career, "JD")

            if not resume_list:
                st.error(t('no_resume'))
            elif not jd_list:
                st.error(t('no_jd'))
            else:
                engine = st.session_state.engine

                # Single Mode
                if len(resume_list) == 1 and len(jd_list) == 1:
                    st.info(t('processing_audit'))
                    try:
                        result = engine.analyze(
                            resume_text=resume_list[0]['content'],
                            jd_text=jd_list[0]['content'],
                            persona=persona_key,
                            use_cache=use_cache,
                            model=model
                        )
                        st.success(t('audit_complete'))

                        # Score and Radar Chart in columns
                        col_score, col_radar = st.columns([1, 2])

                        with col_score:
                            if result.score is not None:
                                color = get_score_color(result.score)
                                st.markdown(f'<h1 style="color:{color}">åŒ¹é…åº¦: {result.score}/100</h1>', unsafe_allow_html=True)

                        with col_radar:
                            radar_data = extract_radar_data(result.report)
                            if radar_data:
                                fig = render_radar_chart(radar_data)
                                if fig:
                                    st.plotly_chart(fig, use_container_width=True)

                        # Report
                        with st.expander("ğŸ“„ æŸ¥çœ‹å®Œæ•´æŠ¥å‘Š", expanded=True):
                            st.markdown(result.report)

                    except Exception as e:
                        st.error(f"åˆ†æå¤±è´¥: {e}")

                # Batch Mode (Resume vs 1 JD)
                elif len(resume_list) > 1 and len(jd_list) == 1:
                    st.info(f"æ­£åœ¨æ‰¹é‡åˆ†æ {len(resume_list)} ä»½ç®€å†...")
                    target_jd = jd_list[0]['content']
                    results = []

                    progress_bar = st.progress(0)
                    for i, res in enumerate(resume_list):
                        try:
                            result = engine.analyze(
                                resume_text=res['content'],
                                jd_text=target_jd,
                                persona=persona_key,
                                use_cache=use_cache,
                                model=model
                            )
                            score = extract_score(result.report)
                            results.append({
                                "Name": res['name'],
                                "Score": score if score else 0,
                                "Report": result.report
                            })
                        except Exception as e:
                            results.append({"Name": res['name'], "Score": 0, "Report": str(e)})
                        progress_bar.progress((i + 1) / len(resume_list))

                    df = pd.DataFrame(results).sort_values(by="Score", ascending=False)
                    st.dataframe(df)
                    st.download_button("ğŸ“¥ ä¸‹è½½CSV", df.to_csv().encode('utf-8'), "results.csv")

# --- Tab 2: Diagnostic (æ·±åº¦è¯Šæ–­) ---
with tab_diag:
    st.markdown("""
    **ğŸ” æ·±åº¦è¯Šæ–­ï¼šæˆ‘æ˜¯è°ï¼Ÿæˆ‘å€¼å¤šå°‘é’±ï¼Ÿ**

    ä¸çœ‹JDï¼Œåªçœ‹ä½ çš„ç®€å†ï¼ŒæŒ–æ˜ä½ å¯èƒ½æ²¡æ„è¯†åˆ°çš„éšæ€§ä»·å€¼ã€‚
    """)

    col1, col2 = st.columns([1, 1])
    with col1:
        st.markdown(f"**{t('resume_label')}**")
        uploaded_resumes_diag = st.file_uploader(
            t('upload_resume'),
            type=['txt', 'md', 'pdf', 'docx'],
            accept_multiple_files=True,
            key="diag_resume"
        )
        resume_text_diag = st.text_area(
            t('paste_resume'),
            height=200,
            key="diag_text"
        )

        # Show parsed preview for diagnostic resume
        if uploaded_resumes_diag:
            for uf in uploaded_resumes_diag:
                content, preview = parse_and_preview_file(uf)
                if content:
                    with st.expander(f"ğŸ“„ å·²è§£æ: {uf.name}", expanded=False):
                        st.text_area("æå–çš„æ–‡æœ¬å†…å®¹", preview, height=150, disabled=True, key=f"preview_diag_{uf.name}")
                else:
                    st.error(preview)

    if st.button(t('btn_diagnostic'), type="primary", use_container_width=True):
        if 'engine' not in st.session_state:
            st.error(t('engine_error'))
        else:
            resume_list = get_content_list(uploaded_resumes_diag, resume_text_diag, "Resume")

            if not resume_list:
                st.error(t('no_resume'))
            else:
                st.info(t('processing_diag'))

                for res in resume_list:
                    try:
                        with st.spinner(f"åˆ†æä¸­..."):
                            result = st.session_state.engine.diagnose_resume(
                                resume_text=res['content'],
                                persona="hrbp",
                                use_cache=use_cache,
                                model=model
                            )

                        st.success(t('diag_complete'))
                        with st.expander("ğŸ“„ æŸ¥çœ‹æ·±åº¦è¯Šæ–­æŠ¥å‘Š", expanded=True):
                            st.markdown(result.report)

                    except Exception as e:
                        st.error(f"åˆ†æå¤±è´¥: {e}")

# --- Tab 3: Side Hustle (å‰¯ä¸šå˜ç°) ---
with tab_hustle:
    st.markdown("""
    **ğŸš€ å‰¯ä¸šå˜ç°ï¼šæŠŠä½ çš„æŠ€èƒ½å˜æˆäº§å“**

    è¾“å…¥ä½ èƒ½æä¾›çš„äº§å“/æœåŠ¡ï¼Œç”Ÿæˆä¸€ä»½è€æ¿æ— æ³•æ‹’ç»çš„JDã€‚
    """)
    st.info(t('btn_hustle'))

# --- Tab 4: Headhunter Mode (çŒå¤´æ¨¡å¼) ---
with tab_headhunter:
    st.markdown("""
    **ğŸ’° çŒå¤´æ¨¡å¼ï¼šæ‰¹é‡ç”Ÿæˆå€™é€‰äººæ¨èæŠ¥å‘Š**
    
    ä¸“ä¸º B ç«¯çŒå¤´/HR è®¾è®¡ã€‚ä¸Šä¼  JD å’Œå¤šä¸ªå€™é€‰äººç®€å†ï¼Œä¸€é”®ç”Ÿæˆå‘é€ç»™ Hiring Manager çš„æ¨èè¯­ (Presentation Note)ã€‚
    """)
    
    col_jd_hh, col_res_hh = st.columns([1, 1])
    
    with col_jd_hh:
        st.markdown("**1. ç›®æ ‡èŒä½ (Target JD)**")
        uploaded_jd_hh = st.file_uploader(
            "ä¸Šä¼  JD (æ”¯æŒå¤šæ–‡ä»¶åˆå¹¶)",
            type=['txt', 'md', 'pdf', 'docx'],
            accept_multiple_files=True,
            key="hh_jd_files"
        )
        jd_text_hh = st.text_area(
            "æˆ–ç²˜è´´ JD å†…å®¹",
            height=200,
            key="hh_jd_text"
        )

    with col_res_hh:
        st.markdown("**2. å€™é€‰äººç®€å† (Batch Upload)**")
        uploaded_resumes_hh = st.file_uploader(
            "æ‰¹é‡ä¸Šä¼ ç®€å† (PDF/Word)",
            type=['txt', 'md', 'pdf', 'docx'],
            accept_multiple_files=True,
            key="hh_resumes"
        )
        # No text paste for batch mode to encourage file workflow

    if st.button(t('btn_headhunter'), type="primary", use_container_width=True):
        if 'engine' not in st.session_state:
            st.error(t('engine_error'))
        else:
            # Prepare JD
            jd_list = get_content_list(uploaded_jd_hh, jd_text_hh, "JD")
            if not jd_list:
                st.error("è¯·æä¾› JDï¼")
            else:
                final_jd = "\n\n".join([j['content'] for j in jd_list])
                
                # Prepare Resumes
                resume_list = get_content_list(uploaded_resumes_hh, "", "Resume")
                
                if not resume_list:
                    st.error("è¯·è‡³å°‘ä¸Šä¼ ä¸€ä»½ç®€å†ï¼")
                else:
                    st.info(f"æ­£åœ¨åˆ†æ {len(resume_list)} ä½å€™é€‰äºº... (ä½¿ç”¨ Persona: Headhunter)")
                    
                    # Force Headhunter Persona
                    engine = st.session_state.engine
                    
                    progress_bar = st.progress(0)
                    
                    for i, res in enumerate(resume_list):
                        with st.expander(f"ğŸ‘¤ å€™é€‰äºº: {res.get('filename', f'Candidate {i+1}')}", expanded=True):
                            try:
                                result = engine.analyze(
                                    resume_text=res['content'],
                                    jd_text=final_jd,
                                    persona="headhunter", # Force this
                                    use_cache=use_cache,
                                    model=model
                                )
                                
                                # Display Score
                                if result.score is not None:
                                    color = get_score_color(result.score)
                                    st.markdown(f"### æ¨èæŒ‡æ•°: <span style='color:{color}'>{result.score}/100</span>", unsafe_allow_html=True)
                                
                                st.markdown(result.report)
                                
                            except Exception as e:
                                st.error(f"åˆ†æå¤±è´¥: {e}")
                        
                        progress_bar.progress((i + 1) / len(resume_list))
                    
                    st.success("âœ… æ‰¹é‡åˆ†æå®Œæˆï¼")


# Footer
st.markdown("---")
st.caption(f"âš¡ {t('footer')}")
